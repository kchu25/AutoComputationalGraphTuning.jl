<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Home · AutoComputationalGraphTuning.jl</title><meta name="title" content="Home · AutoComputationalGraphTuning.jl"/><meta property="og:title" content="Home · AutoComputationalGraphTuning.jl"/><meta property="twitter:title" content="Home · AutoComputationalGraphTuning.jl"/><meta name="description" content="Documentation for AutoComputationalGraphTuning.jl."/><meta property="og:description" content="Documentation for AutoComputationalGraphTuning.jl."/><meta property="twitter:description" content="Documentation for AutoComputationalGraphTuning.jl."/><meta property="og:url" content="https://kchu25.github.io/AutoComputationalGraphTuning.jl/"/><meta property="twitter:url" content="https://kchu25.github.io/AutoComputationalGraphTuning.jl/"/><link rel="canonical" href="https://kchu25.github.io/AutoComputationalGraphTuning.jl/"/><script data-outdated-warner src="assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="assets/documenter.js"></script><script src="search_index.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href>AutoComputationalGraphTuning.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li class="is-active"><a class="tocitem" href>Home</a><ul class="internal"><li><a class="tocitem" href="#Quick-Start"><span>Quick Start</span></a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Home</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Home</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/kchu25/AutoComputationalGraphTuning.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/kchu25/AutoComputationalGraphTuning.jl/blob/main/docs/src/index.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="AutoComputationalGraphTuning"><a class="docs-heading-anchor" href="#AutoComputationalGraphTuning">AutoComputationalGraphTuning</a><a id="AutoComputationalGraphTuning-1"></a><a class="docs-heading-anchor-permalink" href="#AutoComputationalGraphTuning" title="Permalink"></a></h1><p>Documentation for <a href="https://github.com/kchu25/AutoComputationalGraphTuning.jl">AutoComputationalGraphTuning</a>.</p><h2 id="Quick-Start"><a class="docs-heading-anchor" href="#Quick-Start">Quick Start</a><a id="Quick-Start-1"></a><a class="docs-heading-anchor-permalink" href="#Quick-Start" title="Permalink"></a></h2><p>This package makes hyperparameter tuning for Flux models simple. You just need a data struct and a model creation function.</p><h3 id="What-You-Need"><a class="docs-heading-anchor" href="#What-You-Need">What You Need</a><a id="What-You-Need-1"></a><a class="docs-heading-anchor-permalink" href="#What-You-Need" title="Permalink"></a></h3><p><strong>Data struct</strong> with four fields:</p><ul><li><code>data.X</code>, <code>data.Y</code> - your features and labels</li><li><code>data.X_dim</code>, <code>data.Y_dim</code> - dimensions of each feature/label</li></ul><p><strong>Model function</strong> that creates a Flux model:</p><pre><code class="language-julia hljs">function create_model(X_dim, Y_dim, batch_size; rng, use_cuda)
    # Your model code here
    return model  # Must have a `linear_sum` property
end</code></pre><h3 id="Loss-Function-Flexibility"><a class="docs-heading-anchor" href="#Loss-Function-Flexibility">Loss Function Flexibility</a><a id="Loss-Function-Flexibility-1"></a><a class="docs-heading-anchor-permalink" href="#Loss-Function-Flexibility" title="Permalink"></a></h3><p>Want to experiment with different loss functions? Easy:</p><pre><code class="language-julia hljs"># Default MSE
tune_hyperparameters(data, create_model)

# Try MAE instead (less sensitive to outliers)
tune_hyperparameters(data, create_model; 
                    loss_fcn=(loss=Flux.mae, agg=StatsBase.mean))

# Huber loss (robust choice)
tune_hyperparameters(data, create_model;
                    loss_fcn=(loss=Flux.huber_loss, agg=StatsBase.mean))</code></pre><p>The <code>loss_fcn</code> parameter takes any Flux loss function with your choice of aggregation. Works the same way in <code>train_final_model()</code> too.</p><h3 id="Basic-Workflow"><a class="docs-heading-anchor" href="#Basic-Workflow">Basic Workflow</a><a id="Basic-Workflow-1"></a><a class="docs-heading-anchor-permalink" href="#Basic-Workflow" title="Permalink"></a></h3><pre><code class="language-julia hljs"># 1. Tune hyperparameters
results = tune_hyperparameters(data, create_model; 
                              max_epochs=50, n_trials=100)

# 2. Train final model  
model, stats = train_final_model(data, create_model; 
                                seed=42, max_epochs=100)</code></pre><p>The package handles data splitting, normalization, early stopping, and model selection automatically.</p><ul><li><a href="#AutoComputationalGraphTuning.DataSplit"><code>AutoComputationalGraphTuning.DataSplit</code></a></li><li><a href="#AutoComputationalGraphTuning.PreprocessedData"><code>AutoComputationalGraphTuning.PreprocessedData</code></a></li><li><a href="#AutoComputationalGraphTuning.ProcessorEvalStats"><code>AutoComputationalGraphTuning.ProcessorEvalStats</code></a></li><li><a href="#AutoComputationalGraphTuning.ThresholdEvalStats"><code>AutoComputationalGraphTuning.ThresholdEvalStats</code></a></li><li><a href="#AutoComputationalGraphTuning.TrainingConfig"><code>AutoComputationalGraphTuning.TrainingConfig</code></a></li><li><a href="#AutoComputationalGraphTuning._compute_code_gradient_and_linear_output-Tuple{Any, Any, Int64}"><code>AutoComputationalGraphTuning._compute_code_gradient_and_linear_output</code></a></li><li><a href="#AutoComputationalGraphTuning._compute_code_gradients-Tuple{Any, Any, Any, Int64, Int64}"><code>AutoComputationalGraphTuning._compute_code_gradients</code></a></li><li><a href="#AutoComputationalGraphTuning._compute_r2-Union{Tuple{T}, Tuple{AbstractVector{T}, AbstractVector{T}}} where T&lt;:AbstractFloat"><code>AutoComputationalGraphTuning._compute_r2</code></a></li><li><a href="#AutoComputationalGraphTuning._create_eval_dataloaders-Tuple{Any, Any}"><code>AutoComputationalGraphTuning._create_eval_dataloaders</code></a></li><li><a href="#AutoComputationalGraphTuning._create_final_dataloaders-Tuple{Any, Any, Any}"><code>AutoComputationalGraphTuning._create_final_dataloaders</code></a></li><li><a href="#AutoComputationalGraphTuning._evaluate_with_threshold-Union{Tuple{T}, Tuple{Any, Any, Any, T, Int64}} where T&lt;:AbstractFloat"><code>AutoComputationalGraphTuning._evaluate_with_threshold</code></a></li><li><a href="#AutoComputationalGraphTuning._init_processor-Tuple{Any, Any, Bool, Int64}"><code>AutoComputationalGraphTuning._init_processor</code></a></li><li><a href="#AutoComputationalGraphTuning._prepare_final_model_setup-Tuple{Any, Function}"><code>AutoComputationalGraphTuning._prepare_final_model_setup</code></a></li><li><a href="#AutoComputationalGraphTuning._print_summary-NTuple{6, Any}"><code>AutoComputationalGraphTuning._print_summary</code></a></li><li><a href="#AutoComputationalGraphTuning._processor_train_step!-Tuple{Any, Any, Any, Any, Any, Int64, Int64, Int64}"><code>AutoComputationalGraphTuning._processor_train_step!</code></a></li><li><a href="#AutoComputationalGraphTuning._run_trial-NTuple{13, Any}"><code>AutoComputationalGraphTuning._run_trial</code></a></li><li><a href="#AutoComputationalGraphTuning._save_if_best!-NTuple{4, Any}"><code>AutoComputationalGraphTuning._save_if_best!</code></a></li><li><a href="#AutoComputationalGraphTuning._save_trial_config-NTuple{11, Any}"><code>AutoComputationalGraphTuning._save_trial_config</code></a></li><li><a href="#AutoComputationalGraphTuning._setup_save_file-Tuple{Any}"><code>AutoComputationalGraphTuning._setup_save_file</code></a></li><li><a href="#AutoComputationalGraphTuning._train_final_model!-Tuple{Any, Any, Any}"><code>AutoComputationalGraphTuning._train_final_model!</code></a></li><li><a href="#AutoComputationalGraphTuning._train_processor_epoch!-Tuple{Any, Any, Any, Any, Any, Int64, Int64, Ref{Int64}}"><code>AutoComputationalGraphTuning._train_processor_epoch!</code></a></li><li><a href="#AutoComputationalGraphTuning._update_best!-NTuple{6, Any}"><code>AutoComputationalGraphTuning._update_best!</code></a></li><li><a href="#AutoComputationalGraphTuning.check_early_stopping!-NTuple{9, Any}"><code>AutoComputationalGraphTuning.check_early_stopping!</code></a></li><li><a href="#AutoComputationalGraphTuning.compile_loss-Tuple{NamedTuple{(:loss, :agg), &lt;:Tuple{var&quot;#s2&quot;, var&quot;#s1&quot;} where {var&quot;#s2&quot;&lt;:Function, var&quot;#s1&quot;&lt;:Function}}}"><code>AutoComputationalGraphTuning.compile_loss</code></a></li><li><a href="#AutoComputationalGraphTuning.compute_r2_scores-Tuple{Any, Any, Any}"><code>AutoComputationalGraphTuning.compute_r2_scores</code></a></li><li><a href="#AutoComputationalGraphTuning.evaluate_processor-Tuple{Any, Any, Any, String}"><code>AutoComputationalGraphTuning.evaluate_processor</code></a></li><li><a href="#AutoComputationalGraphTuning.evaluate_validation_loss-Tuple{Any, Any}"><code>AutoComputationalGraphTuning.evaluate_validation_loss</code></a></li><li><a href="#AutoComputationalGraphTuning.evaluate_validation_metrics-Tuple{Any, Any, Any}"><code>AutoComputationalGraphTuning.evaluate_validation_metrics</code></a></li><li><a href="#AutoComputationalGraphTuning.find_optimal_threshold-Union{Tuple{T}, Tuple{Any, Any, Any, Any, AutoComputationalGraphTuning.ProcessorEvalStats{T}}} where T&lt;:AbstractFloat"><code>AutoComputationalGraphTuning.find_optimal_threshold</code></a></li><li><a href="#AutoComputationalGraphTuning.get_function_name-Tuple{Any}"><code>AutoComputationalGraphTuning.get_function_name</code></a></li><li><a href="#AutoComputationalGraphTuning.get_split_indices-Tuple{Int64}"><code>AutoComputationalGraphTuning.get_split_indices</code></a></li><li><a href="#AutoComputationalGraphTuning.leading_colons-Tuple{AbstractArray}"><code>AutoComputationalGraphTuning.leading_colons</code></a></li><li><a href="#AutoComputationalGraphTuning.load_best_trial_config-Tuple{String}"><code>AutoComputationalGraphTuning.load_best_trial_config</code></a></li><li><a href="#AutoComputationalGraphTuning.load_trial_config-Tuple{String}"><code>AutoComputationalGraphTuning.load_trial_config</code></a></li><li><a href="#AutoComputationalGraphTuning.masked_loss"><code>AutoComputationalGraphTuning.masked_loss</code></a></li><li><a href="#AutoComputationalGraphTuning.print_epoch_summary-NTuple{6, Any}"><code>AutoComputationalGraphTuning.print_epoch_summary</code></a></li><li><a href="#AutoComputationalGraphTuning.save_trial_config-Tuple{TrainingConfig, String}"><code>AutoComputationalGraphTuning.save_trial_config</code></a></li><li><a href="#AutoComputationalGraphTuning.set_reproducible_seeds!"><code>AutoComputationalGraphTuning.set_reproducible_seeds!</code></a></li><li><a href="#AutoComputationalGraphTuning.train_batch!-NTuple{4, Any}"><code>AutoComputationalGraphTuning.train_batch!</code></a></li><li><a href="#AutoComputationalGraphTuning.train_code_processor-Tuple{Any, Any, Any}"><code>AutoComputationalGraphTuning.train_code_processor</code></a></li><li><a href="#AutoComputationalGraphTuning.train_epoch!-NTuple{5, Any}"><code>AutoComputationalGraphTuning.train_epoch!</code></a></li><li><a href="#AutoComputationalGraphTuning.train_final_model-Tuple{Any, Function}"><code>AutoComputationalGraphTuning.train_final_model</code></a></li><li><a href="#AutoComputationalGraphTuning.train_final_model_from_config-Tuple{Any, Function, TrainingConfig, Any}"><code>AutoComputationalGraphTuning.train_final_model_from_config</code></a></li><li><a href="#AutoComputationalGraphTuning.train_model-NTuple{5, Any}"><code>AutoComputationalGraphTuning.train_model</code></a></li><li><a href="#AutoComputationalGraphTuning.train_val_test_split-Tuple{Any}"><code>AutoComputationalGraphTuning.train_val_test_split</code></a></li><li><a href="#AutoComputationalGraphTuning.tune_hyperparameters-Tuple{Any, Function}"><code>AutoComputationalGraphTuning.tune_hyperparameters</code></a></li></ul><article><details class="docstring" open="true"><summary id="AutoComputationalGraphTuning.DataSplit"><a class="docstring-binding" href="#AutoComputationalGraphTuning.DataSplit"><code>AutoComputationalGraphTuning.DataSplit</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">DataSplit</code></pre><p>Represents a single data split with tensor and labels.</p><p><strong>Fields</strong></p><ul><li><code>tensor</code>: Encoded sequence tensor (e.g. 4D array)</li><li><code>labels</code>: Labels (vector or matrix)</li><li><code>stats</code>: Normalization statistics (only present for training data when normalized)</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/AutoComputationalGraphTuning.jl/blob/04bc0ca4dc3d73d399fa86f9711e182f3cb7939f/src/_data_splitting/structs.jl#L4-L13">source</a></section></details></article><article><details class="docstring" open="true"><summary id="AutoComputationalGraphTuning.PreprocessedData"><a class="docstring-binding" href="#AutoComputationalGraphTuning.PreprocessedData"><code>AutoComputationalGraphTuning.PreprocessedData</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">PreprocessedData</code></pre><p>Container for preprocessed train/validation/test splits.</p><p><strong>Fields</strong></p><ul><li><code>train</code>: Training data split</li><li><code>val</code>: Validation data split</li><li><code>test</code>: Test data split</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/AutoComputationalGraphTuning.jl/blob/04bc0ca4dc3d73d399fa86f9711e182f3cb7939f/src/_data_splitting/structs.jl#L30-L39">source</a></section></details></article><article><details class="docstring" open="true"><summary id="AutoComputationalGraphTuning.ProcessorEvalStats"><a class="docstring-binding" href="#AutoComputationalGraphTuning.ProcessorEvalStats"><code>AutoComputationalGraphTuning.ProcessorEvalStats</code></a> — <span class="docstring-category">Type</span></summary><section><div><p>Statistics for processor evaluation</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/AutoComputationalGraphTuning.jl/blob/04bc0ca4dc3d73d399fa86f9711e182f3cb7939f/src/final_and_code/code_processor_eval.jl#L1">source</a></section></details></article><article><details class="docstring" open="true"><summary id="AutoComputationalGraphTuning.ThresholdEvalStats"><a class="docstring-binding" href="#AutoComputationalGraphTuning.ThresholdEvalStats"><code>AutoComputationalGraphTuning.ThresholdEvalStats</code></a> — <span class="docstring-category">Type</span></summary><section><div><p>Statistics for threshold evaluation</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/AutoComputationalGraphTuning.jl/blob/04bc0ca4dc3d73d399fa86f9711e182f3cb7939f/src/final_and_code/gyro_thresh.jl#L1">source</a></section></details></article><article><details class="docstring" open="true"><summary id="AutoComputationalGraphTuning.TrainingConfig"><a class="docstring-binding" href="#AutoComputationalGraphTuning.TrainingConfig"><code>AutoComputationalGraphTuning.TrainingConfig</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">TrainingConfig</code></pre><p>Configuration for model training, including all hyperparameters and settings. This struct is used to save/load trial configurations for reproducibility.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/AutoComputationalGraphTuning.jl/blob/04bc0ca4dc3d73d399fa86f9711e182f3cb7939f/src/config_management.jl#L25-L30">source</a></section></details></article><article><details class="docstring" open="true"><summary id="AutoComputationalGraphTuning._compute_code_gradient_and_linear_output-Tuple{Any, Any, Int64}"><a class="docstring-binding" href="#AutoComputationalGraphTuning._compute_code_gradient_and_linear_output-Tuple{Any, Any, Int64}"><code>AutoComputationalGraphTuning._compute_code_gradient_and_linear_output</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Compute code gradient and linear (pre-activation) output for a single batch</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/AutoComputationalGraphTuning.jl/blob/04bc0ca4dc3d73d399fa86f9711e182f3cb7939f/src/final_and_code/code_processor_eval.jl#L13">source</a></section></details></article><article><details class="docstring" open="true"><summary id="AutoComputationalGraphTuning._compute_code_gradients-Tuple{Any, Any, Any, Int64, Int64}"><a class="docstring-binding" href="#AutoComputationalGraphTuning._compute_code_gradients-Tuple{Any, Any, Any, Int64, Int64}"><code>AutoComputationalGraphTuning._compute_code_gradients</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Compute predictions and gradients w.r.t. code</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/AutoComputationalGraphTuning.jl/blob/04bc0ca4dc3d73d399fa86f9711e182f3cb7939f/src/final_and_code/_helpers.jl#L60">source</a></section></details></article><article><details class="docstring" open="true"><summary id="AutoComputationalGraphTuning._compute_r2-Union{Tuple{T}, Tuple{AbstractVector{T}, AbstractVector{T}}} where T&lt;:AbstractFloat"><a class="docstring-binding" href="#AutoComputationalGraphTuning._compute_r2-Union{Tuple{T}, Tuple{AbstractVector{T}, AbstractVector{T}}} where T&lt;:AbstractFloat"><code>AutoComputationalGraphTuning._compute_r2</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Compute R² coefficient, excluding NaN values</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/AutoComputationalGraphTuning.jl/blob/04bc0ca4dc3d73d399fa86f9711e182f3cb7939f/src/final_and_code/code_processor_eval.jl#L24">source</a></section></details></article><article><details class="docstring" open="true"><summary id="AutoComputationalGraphTuning._create_eval_dataloaders-Tuple{Any, Any}"><a class="docstring-binding" href="#AutoComputationalGraphTuning._create_eval_dataloaders-Tuple{Any, Any}"><code>AutoComputationalGraphTuning._create_eval_dataloaders</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Create eval dataloaders with no shuffling and partial=true so every sample is included and order matches split<em>indices. Returns: (dl</em>train<em>eval, dl</em>test_eval)</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/AutoComputationalGraphTuning.jl/blob/04bc0ca4dc3d73d399fa86f9711e182f3cb7939f/src/final_and_code/_helpers.jl#L30-L33">source</a></section></details></article><article><details class="docstring" open="true"><summary id="AutoComputationalGraphTuning._create_final_dataloaders-Tuple{Any, Any, Any}"><a class="docstring-binding" href="#AutoComputationalGraphTuning._create_final_dataloaders-Tuple{Any, Any, Any}"><code>AutoComputationalGraphTuning._create_final_dataloaders</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Create dataloaders for final model training. Returns: (dl<em>train, dl</em>test)</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/AutoComputationalGraphTuning.jl/blob/04bc0ca4dc3d73d399fa86f9711e182f3cb7939f/src/final_and_code/_helpers.jl#L21">source</a></section></details></article><article><details class="docstring" open="true"><summary id="AutoComputationalGraphTuning._evaluate_with_threshold-Union{Tuple{T}, Tuple{Any, Any, Any, T, Int64}} where T&lt;:AbstractFloat"><a class="docstring-binding" href="#AutoComputationalGraphTuning._evaluate_with_threshold-Union{Tuple{T}, Tuple{Any, Any, Any, T, Int64}} where T&lt;:AbstractFloat"><code>AutoComputationalGraphTuning._evaluate_with_threshold</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Evaluate processor performance with a specific threshold applied to proc_gyro·code products.</p><p><strong>Arguments</strong></p><ul><li><code>model</code>: Trained model</li><li><code>processor</code>: Trained code processor</li><li><code>dataloader</code>: DataLoader for evaluation</li><li><code>threshold</code>: Magnitude threshold for masking proc_gyro·code product components</li><li><code>predict_position</code>: Position for prediction</li></ul><p><strong>Returns</strong></p><p><code>ThresholdEvalStats</code> containing R² scores and sparsity metrics</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/AutoComputationalGraphTuning.jl/blob/04bc0ca4dc3d73d399fa86f9711e182f3cb7939f/src/final_and_code/gyro_thresh.jl#L155-L167">source</a></section></details></article><article><details class="docstring" open="true"><summary id="AutoComputationalGraphTuning._init_processor-Tuple{Any, Any, Bool, Int64}"><a class="docstring-binding" href="#AutoComputationalGraphTuning._init_processor-Tuple{Any, Any, Bool, Int64}"><code>AutoComputationalGraphTuning._init_processor</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Initialize processor and optimizer with seeded RNG</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/AutoComputationalGraphTuning.jl/blob/04bc0ca4dc3d73d399fa86f9711e182f3cb7939f/src/final_and_code/_helpers.jl#L52">source</a></section></details></article><article><details class="docstring" open="true"><summary id="AutoComputationalGraphTuning._prepare_final_model_setup-Tuple{Any, Function}"><a class="docstring-binding" href="#AutoComputationalGraphTuning._prepare_final_model_setup-Tuple{Any, Function}"><code>AutoComputationalGraphTuning._prepare_final_model_setup</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Prepare setup for final model training. Returns: (setup, batch_size)</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/AutoComputationalGraphTuning.jl/blob/04bc0ca4dc3d73d399fa86f9711e182f3cb7939f/src/final_and_code/_helpers.jl#L3">source</a></section></details></article><article><details class="docstring" open="true"><summary id="AutoComputationalGraphTuning._print_summary-NTuple{6, Any}"><a class="docstring-binding" href="#AutoComputationalGraphTuning._print_summary-NTuple{6, Any}"><code>AutoComputationalGraphTuning._print_summary</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Print final tuning summary.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/AutoComputationalGraphTuning.jl/blob/04bc0ca4dc3d73d399fa86f9711e182f3cb7939f/src/tune/_helpers.jl#L87">source</a></section></details></article><article><details class="docstring" open="true"><summary id="AutoComputationalGraphTuning._processor_train_step!-Tuple{Any, Any, Any, Any, Any, Int64, Int64, Int64}"><a class="docstring-binding" href="#AutoComputationalGraphTuning._processor_train_step!-Tuple{Any, Any, Any, Any, Any, Int64, Int64, Int64}"><code>AutoComputationalGraphTuning._processor_train_step!</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Single training step for code processor</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/AutoComputationalGraphTuning.jl/blob/04bc0ca4dc3d73d399fa86f9711e182f3cb7939f/src/final_and_code/_helpers.jl#L72">source</a></section></details></article><article><details class="docstring" open="true"><summary id="AutoComputationalGraphTuning._run_trial-NTuple{13, Any}"><a class="docstring-binding" href="#AutoComputationalGraphTuning._run_trial-NTuple{13, Any}"><code>AutoComputationalGraphTuning._run_trial</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Run a single hyperparameter tuning trial.</p><p><strong>Returns: (r2, val<em>loss, num</em>params, model<em>state, model, batch</em>size)</strong></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/AutoComputationalGraphTuning.jl/blob/04bc0ca4dc3d73d399fa86f9711e182f3cb7939f/src/tune/_helpers.jl#L21-L25">source</a></section></details></article><article><details class="docstring" open="true"><summary id="AutoComputationalGraphTuning._save_if_best!-NTuple{4, Any}"><a class="docstring-binding" href="#AutoComputationalGraphTuning._save_if_best!-NTuple{4, Any}"><code>AutoComputationalGraphTuning._save_if_best!</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Save results if current trial is best.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/AutoComputationalGraphTuning.jl/blob/04bc0ca4dc3d73d399fa86f9711e182f3cb7939f/src/tune/_helpers.jl#L6">source</a></section></details></article><article><details class="docstring" open="true"><summary id="AutoComputationalGraphTuning._save_trial_config-NTuple{11, Any}"><a class="docstring-binding" href="#AutoComputationalGraphTuning._save_trial_config-NTuple{11, Any}"><code>AutoComputationalGraphTuning._save_trial_config</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Save trial configuration to JSON file.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/AutoComputationalGraphTuning.jl/blob/04bc0ca4dc3d73d399fa86f9711e182f3cb7939f/src/tune/_helpers.jl#L57">source</a></section></details></article><article><details class="docstring" open="true"><summary id="AutoComputationalGraphTuning._setup_save_file-Tuple{Any}"><a class="docstring-binding" href="#AutoComputationalGraphTuning._setup_save_file-Tuple{Any}"><code>AutoComputationalGraphTuning._setup_save_file</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Setup save file path with timestamp.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/AutoComputationalGraphTuning.jl/blob/04bc0ca4dc3d73d399fa86f9711e182f3cb7939f/src/tune/_helpers.jl#L3">source</a></section></details></article><article><details class="docstring" open="true"><summary id="AutoComputationalGraphTuning._train_final_model!-Tuple{Any, Any, Any}"><a class="docstring-binding" href="#AutoComputationalGraphTuning._train_final_model!-Tuple{Any, Any, Any}"><code>AutoComputationalGraphTuning._train_final_model!</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Train final model and load best weights. Returns: (trained_model, stats)</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/AutoComputationalGraphTuning.jl/blob/04bc0ca4dc3d73d399fa86f9711e182f3cb7939f/src/final_and_code/_helpers.jl#L42">source</a></section></details></article><article><details class="docstring" open="true"><summary id="AutoComputationalGraphTuning._train_processor_epoch!-Tuple{Any, Any, Any, Any, Any, Int64, Int64, Ref{Int64}}"><a class="docstring-binding" href="#AutoComputationalGraphTuning._train_processor_epoch!-Tuple{Any, Any, Any, Any, Any, Int64, Int64, Ref{Int64}}"><code>AutoComputationalGraphTuning._train_processor_epoch!</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Train epoch for code processor</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/AutoComputationalGraphTuning.jl/blob/04bc0ca4dc3d73d399fa86f9711e182f3cb7939f/src/final_and_code/_helpers.jl#L87">source</a></section></details></article><article><details class="docstring" open="true"><summary id="AutoComputationalGraphTuning._update_best!-NTuple{6, Any}"><a class="docstring-binding" href="#AutoComputationalGraphTuning._update_best!-NTuple{6, Any}"><code>AutoComputationalGraphTuning._update_best!</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Update best model if current trial is better.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/AutoComputationalGraphTuning.jl/blob/04bc0ca4dc3d73d399fa86f9711e182f3cb7939f/src/tune/_helpers.jl#L77">source</a></section></details></article><article><details class="docstring" open="true"><summary id="AutoComputationalGraphTuning.check_early_stopping!-NTuple{9, Any}"><a class="docstring-binding" href="#AutoComputationalGraphTuning.check_early_stopping!-NTuple{9, Any}"><code>AutoComputationalGraphTuning.check_early_stopping!</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Check early stopping condition and update best model state</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/AutoComputationalGraphTuning.jl/blob/04bc0ca4dc3d73d399fa86f9711e182f3cb7939f/src/_training/check_state.jl#L1">source</a></section></details></article><article><details class="docstring" open="true"><summary id="AutoComputationalGraphTuning.compile_loss-Tuple{NamedTuple{(:loss, :agg), &lt;:Tuple{var&quot;#s2&quot;, var&quot;#s1&quot;} where {var&quot;#s2&quot;&lt;:Function, var&quot;#s1&quot;&lt;:Function}}}"><a class="docstring-binding" href="#AutoComputationalGraphTuning.compile_loss-Tuple{NamedTuple{(:loss, :agg), &lt;:Tuple{var&quot;#s2&quot;, var&quot;#s1&quot;} where {var&quot;#s2&quot;&lt;:Function, var&quot;#s1&quot;&lt;:Function}}}"><code>AutoComputationalGraphTuning.compile_loss</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">compile_loss(loss_spec) -&gt; compiled_loss(predictions, targets, mask)</code></pre><p>Compile a loss specification (NamedTuple) into a callable 3-arg loss function.</p><p><strong>Arguments</strong></p><ul><li><code>loss_spec</code>: Named tuple <code>(loss=loss_function, agg=aggregation_function)</code></li></ul><p><strong>Returns</strong></p><ul><li><code>compiled_loss</code>: Function <code>(predictions, targets, mask) -&gt; scalar</code></li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs"># Compile MSE loss with mean aggregation
compiled = compile_loss((loss=Flux.mse, agg=StatsBase.mean))

# Compile MAE loss with sum aggregation
compiled = compile_loss((loss=Flux.mae, agg=sum))

# Use in training
loss = compiled(predictions, targets, mask)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/AutoComputationalGraphTuning.jl/blob/04bc0ca4dc3d73d399fa86f9711e182f3cb7939f/src/_training/loss.jl#L40-L62">source</a></section></details></article><article><details class="docstring" open="true"><summary id="AutoComputationalGraphTuning.compute_r2_scores-Tuple{Any, Any, Any}"><a class="docstring-binding" href="#AutoComputationalGraphTuning.compute_r2_scores-Tuple{Any, Any, Any}"><code>AutoComputationalGraphTuning.compute_r2_scores</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">compute_r2_scores(predictions, targets, mask)</code></pre><p>Compute R² scores for individual RBPs and aggregated across all predictions.</p><p><strong>Arguments</strong></p><ul><li><code>predictions</code>: Model predictions matrix (n<em>rbps, n</em>samples)</li><li><code>targets</code>: Ground truth targets matrix (n<em>rbps, n</em>samples)  </li><li><code>mask</code>: Boolean mask for valid entries (n<em>rbps, n</em>samples)</li></ul><p><strong>Returns</strong></p><ul><li><code>individual_r2</code>: R² score for each RBP (may contain NaN for insufficient data)</li><li><code>aggregated_r2</code>: Overall R² across all valid predictions</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/AutoComputationalGraphTuning.jl/blob/04bc0ca4dc3d73d399fa86f9711e182f3cb7939f/src/_training/eval.jl#L34-L47">source</a></section></details></article><article><details class="docstring" open="true"><summary id="AutoComputationalGraphTuning.evaluate_processor-Tuple{Any, Any, Any, String}"><a class="docstring-binding" href="#AutoComputationalGraphTuning.evaluate_processor-Tuple{Any, Any, Any, String}"><code>AutoComputationalGraphTuning.evaluate_processor</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Evaluate code processor performance on a dataset.</p><p><strong>Arguments</strong></p><ul><li><code>model</code>: Trained model</li><li><code>processor</code>: Trained code processor</li><li><code>dataloader</code>: DataLoader for evaluation</li><li><code>set_name</code>: Name of the dataset (e.g., &quot;Train&quot;, &quot;Test&quot;)</li><li><code>predict_position</code>: Position for prediction (default: 1)</li></ul><p><strong>Returns</strong></p><p><code>ProcessorEvalStats</code> containing R² scores for original gradients vs processor gradients</p><p><strong>Example</strong></p><pre><code class="language-julia hljs">stats_train = evaluate_processor(m, processor, dl_train, &quot;Train&quot;)
stats_test = evaluate_processor(m, processor, dl_test, &quot;Test&quot;)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/AutoComputationalGraphTuning.jl/blob/04bc0ca4dc3d73d399fa86f9711e182f3cb7939f/src/final_and_code/code_processor_eval.jl#L41-L59">source</a></section></details></article><article><details class="docstring" open="true"><summary id="AutoComputationalGraphTuning.evaluate_validation_loss-Tuple{Any, Any}"><a class="docstring-binding" href="#AutoComputationalGraphTuning.evaluate_validation_loss-Tuple{Any, Any}"><code>AutoComputationalGraphTuning.evaluate_validation_loss</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">evaluate_validation_loss(model, hp, dataloader)</code></pre><p>Evaluate validation loss using masked MSE for NaN handling.</p><p><strong>Arguments</strong></p><ul><li><code>model</code>: Trained model instance</li><li><code>hp</code>: HyperParameters </li><li><code>dataloader</code>: Validation data loader</li></ul><p><strong>Returns</strong></p><ul><li>Average validation loss over all batches</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/AutoComputationalGraphTuning.jl/blob/04bc0ca4dc3d73d399fa86f9711e182f3cb7939f/src/_training/eval.jl#L2-L14">source</a></section></details></article><article><details class="docstring" open="true"><summary id="AutoComputationalGraphTuning.evaluate_validation_metrics-Tuple{Any, Any, Any}"><a class="docstring-binding" href="#AutoComputationalGraphTuning.evaluate_validation_metrics-Tuple{Any, Any, Any}"><code>AutoComputationalGraphTuning.evaluate_validation_metrics</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">evaluate_validation_metrics(model, dataloader, n_outputs)</code></pre><p>Evaluate comprehensive validation metrics including loss and R² scores.</p><p><strong>Arguments</strong></p><ul><li><code>model</code>: Trained model instance</li><li><code>dataloader</code>: Validation data loader  </li><li><code>n_outputs</code>: Number of output targets (RBPs)</li></ul><p><strong>Returns</strong></p><ul><li><code>avg_loss</code>: Average validation loss</li><li><code>individual_r2</code>: R² score for each RBP</li><li><code>aggregated_r2</code>: Overall R² across all predictions</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/AutoComputationalGraphTuning.jl/blob/04bc0ca4dc3d73d399fa86f9711e182f3cb7939f/src/_training/eval.jl#L95-L109">source</a></section></details></article><article><details class="docstring" open="true"><summary id="AutoComputationalGraphTuning.find_optimal_threshold-Union{Tuple{T}, Tuple{Any, Any, Any, Any, AutoComputationalGraphTuning.ProcessorEvalStats{T}}} where T&lt;:AbstractFloat"><a class="docstring-binding" href="#AutoComputationalGraphTuning.find_optimal_threshold-Union{Tuple{T}, Tuple{Any, Any, Any, Any, AutoComputationalGraphTuning.ProcessorEvalStats{T}}} where T&lt;:AbstractFloat"><code>AutoComputationalGraphTuning.find_optimal_threshold</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Find optimal threshold for proc_gyro that maximizes sparsity while maintaining R² performance.</p><p>Searches for the highest threshold where masking proc_gyro·code products below threshold still maintains acceptable R² on the test set compared to the baseline processor R².</p><p><strong>Arguments</strong></p><ul><li><code>model</code>: Trained model</li><li><code>processor</code>: Trained code processor</li><li><code>dataloader_train</code>: Training data loader (for finding threshold)</li><li><code>dataloader_test</code>: Test data loader (for evaluating R²)</li><li><code>baseline_stats</code>: ProcessorEvalStats from evaluate<em>processor (contains baseline r2</em>processor)</li><li><code>r2_tolerance</code>: Maximum acceptable R² drop (default: 0.05, meaning max 5% relative drop)</li><li><code>num_candidates</code>: Number of threshold values to test (default: 20)</li><li><code>predict_position</code>: Position for prediction (default: 1)</li></ul><p><strong>Returns</strong></p><p><code>ThresholdEvalStats</code> containing optimal threshold and performance metrics</p><p><strong>Example</strong></p><pre><code class="language-julia hljs"># First get baseline performance
baseline = evaluate_processor(m, processor, dl_test, &quot;Test&quot;)
# Then find optimal threshold
thresh_stats = find_optimal_threshold(m, processor, dl_train, dl_test, baseline)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/AutoComputationalGraphTuning.jl/blob/04bc0ca4dc3d73d399fa86f9711e182f3cb7939f/src/final_and_code/gyro_thresh.jl#L34-L60">source</a></section></details></article><article><details class="docstring" open="true"><summary id="AutoComputationalGraphTuning.get_function_name-Tuple{Any}"><a class="docstring-binding" href="#AutoComputationalGraphTuning.get_function_name-Tuple{Any}"><code>AutoComputationalGraphTuning.get_function_name</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">get_function_name(f)</code></pre><p>Get the fully qualified name of a function, preserving module prefix. For common StatsBase re-exports (like mean), prefer StatsBase module name.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/AutoComputationalGraphTuning.jl/blob/04bc0ca4dc3d73d399fa86f9711e182f3cb7939f/src/config_management.jl#L6-L11">source</a></section></details></article><article><details class="docstring" open="true"><summary id="AutoComputationalGraphTuning.get_split_indices-Tuple{Int64}"><a class="docstring-binding" href="#AutoComputationalGraphTuning.get_split_indices-Tuple{Int64}"><code>AutoComputationalGraphTuning.get_split_indices</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">get_split_indices(data_size::Int; train_ratio=0.8, val_ratio=0.1, test_ratio=0.1, shuffle=true, seed=nothing)</code></pre><p>Return shuffled (or ordered) indices for train/validation/test splits.</p><p><strong>Arguments</strong></p><ul><li><code>data_size</code>: Number of data points</li><li><code>train_ratio</code>, <code>val_ratio</code>, <code>test_ratio</code>: Proportions for each split (must sum to 1)</li><li><code>shuffle</code>: Shuffle indices (default: true)</li><li><code>seed</code>: Random seed (optional)</li></ul><p><strong>Returns</strong></p><ul><li>Named tuple: <code>(train, val, test)</code> index vectors</li></ul><p><strong>Throws</strong></p><ul><li><code>ArgumentError</code> if ratios are invalid or data_size &lt;= 0</li></ul><p><strong>Example</strong></p><p>train<em>idx, val</em>idx, test<em>idx = get</em>split_indices(1000; seed=42)</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/AutoComputationalGraphTuning.jl/blob/04bc0ca4dc3d73d399fa86f9711e182f3cb7939f/src/_data_splitting/indexing.jl#L1-L22">source</a></section></details></article><article><details class="docstring" open="true"><summary id="AutoComputationalGraphTuning.leading_colons-Tuple{AbstractArray}"><a class="docstring-binding" href="#AutoComputationalGraphTuning.leading_colons-Tuple{AbstractArray}"><code>AutoComputationalGraphTuning.leading_colons</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">leading_colons(x::AbstractArray)</code></pre><p>Return a tuple of <code>:</code> (colons) of length <code>ndims(x) - 1</code>. Useful for slicing all but the last dimension of an array.</p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">A = rand(3, 4, 5)
A[leading_colons(A)..., 2]  # selects all elements in the last dimension at index 2</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/AutoComputationalGraphTuning.jl/blob/04bc0ca4dc3d73d399fa86f9711e182f3cb7939f/src/_data_splitting/split.jl#L1-L12">source</a></section></details></article><article><details class="docstring" open="true"><summary id="AutoComputationalGraphTuning.load_best_trial_config-Tuple{String}"><a class="docstring-binding" href="#AutoComputationalGraphTuning.load_best_trial_config-Tuple{String}"><code>AutoComputationalGraphTuning.load_best_trial_config</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">load_best_trial_config(save_folder::String)</code></pre><p>Load the configuration for the best trial (highest R²) from a tuning run. Reads the CSV results file and loads the corresponding JSON config.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/AutoComputationalGraphTuning.jl/blob/04bc0ca4dc3d73d399fa86f9711e182f3cb7939f/src/config_management.jl#L84-L89">source</a></section></details></article><article><details class="docstring" open="true"><summary id="AutoComputationalGraphTuning.load_trial_config-Tuple{String}"><a class="docstring-binding" href="#AutoComputationalGraphTuning.load_trial_config-Tuple{String}"><code>AutoComputationalGraphTuning.load_trial_config</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">load_trial_config(json_path::String)</code></pre><p>Load a trial configuration from a JSON file.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/AutoComputationalGraphTuning.jl/blob/04bc0ca4dc3d73d399fa86f9711e182f3cb7939f/src/config_management.jl#L70-L74">source</a></section></details></article><article><details class="docstring" open="true"><summary id="AutoComputationalGraphTuning.masked_loss"><a class="docstring-binding" href="#AutoComputationalGraphTuning.masked_loss"><code>AutoComputationalGraphTuning.masked_loss</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">masked_loss(predictions, targets, mask, loss_fcn, agg)</code></pre><p>Apply any Flux loss function only on valid (masked) entries.</p><p><strong>Arguments</strong></p><ul><li><code>predictions</code>: Model predictions</li><li><code>targets</code>: Ground truth targets  </li><li><code>mask</code>: Boolean mask indicating valid entries</li><li><code>loss_fcn</code>: Flux loss function (e.g., Flux.mse, Flux.mae, Flux.huber_loss)</li><li><code>agg</code>: Aggregation function (default: StatsBase.mean)</li></ul><p><strong>Returns</strong></p><ul><li>Loss computed only on valid entries specified by mask</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs"># MSE with mean aggregation (default)
loss = masked_loss(ŷ, y, mask, Flux.mse, StatsBase.mean)

# MAE with sum aggregation  
loss = masked_loss(ŷ, y, mask, Flux.mae, sum)

# Huber loss with mean aggregation
loss = masked_loss(ŷ, y, mask, Flux.huber_loss, StatsBase.mean)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/AutoComputationalGraphTuning.jl/blob/04bc0ca4dc3d73d399fa86f9711e182f3cb7939f/src/_training/loss.jl#L1-L27">source</a></section></details></article><article><details class="docstring" open="true"><summary id="AutoComputationalGraphTuning.print_epoch_summary-NTuple{6, Any}"><a class="docstring-binding" href="#AutoComputationalGraphTuning.print_epoch_summary-NTuple{6, Any}"><code>AutoComputationalGraphTuning.print_epoch_summary</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Print epoch summary with training and validation metrics</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/AutoComputationalGraphTuning.jl/blob/04bc0ca4dc3d73d399fa86f9711e182f3cb7939f/src/_training/log.jl#L2">source</a></section></details></article><article><details class="docstring" open="true"><summary id="AutoComputationalGraphTuning.save_trial_config-Tuple{TrainingConfig, String}"><a class="docstring-binding" href="#AutoComputationalGraphTuning.save_trial_config-Tuple{TrainingConfig, String}"><code>AutoComputationalGraphTuning.save_trial_config</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">save_trial_config(config::TrainingConfig, save_folder::String)</code></pre><p>Save a trial configuration to a JSON file in the <code>json</code> subfolder.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/AutoComputationalGraphTuning.jl/blob/04bc0ca4dc3d73d399fa86f9711e182f3cb7939f/src/config_management.jl#L48-L52">source</a></section></details></article><article><details class="docstring" open="true"><summary id="AutoComputationalGraphTuning.set_reproducible_seeds!"><a class="docstring-binding" href="#AutoComputationalGraphTuning.set_reproducible_seeds!"><code>AutoComputationalGraphTuning.set_reproducible_seeds!</code></a> — <span class="docstring-category">Function</span></summary><section><div><p>Set all random seeds for reproducible results</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/AutoComputationalGraphTuning.jl/blob/04bc0ca4dc3d73d399fa86f9711e182f3cb7939f/src/utils.jl#L1">source</a></section></details></article><article><details class="docstring" open="true"><summary id="AutoComputationalGraphTuning.train_batch!-NTuple{4, Any}"><a class="docstring-binding" href="#AutoComputationalGraphTuning.train_batch!-NTuple{4, Any}"><code>AutoComputationalGraphTuning.train_batch!</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Train single batch with flexible loss computation.</p><p><strong>Arguments</strong></p><ul><li><code>model</code>: The model to train</li><li><code>opt_state</code>: Optimizer state</li><li><code>seq, labels</code>: Batch data</li><li><code>compute_loss</code>: Function(model, seq, labels, nan<em>mask) -&gt; (loss, aux</em>info)<ul><li>Should return loss scalar and optionally auxiliary info dict</li><li>Default: standard masked MSE loss</li></ul></li></ul><p><strong>Returns</strong></p><ul><li><code>loss</code>: Scalar loss value</li><li><code>aux_info</code>: Dict with auxiliary information (e.g., valid_count, regularizers, etc.)</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/AutoComputationalGraphTuning.jl/blob/04bc0ca4dc3d73d399fa86f9711e182f3cb7939f/src/_training/train.jl#L1-L15">source</a></section></details></article><article><details class="docstring" open="true"><summary id="AutoComputationalGraphTuning.train_code_processor-Tuple{Any, Any, Any}"><a class="docstring-binding" href="#AutoComputationalGraphTuning.train_code_processor-Tuple{Any, Any, Any}"><code>AutoComputationalGraphTuning.train_code_processor</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Train a code processor to learn gradient transformations.</p><p><strong>Arguments</strong></p><ul><li><code>model</code>: Pre-trained model (frozen during training)</li><li><code>dataloader</code>: Training DataLoader</li><li><code>proc_wrap</code>: Named tuple with (create<em>processor, arch</em>type, predict<em>from</em>code, process_code)</li><li><code>seed</code>: Random seed (default: 42)</li><li><code>max_epochs</code>: Training epochs (default: 20)</li><li><code>predict_position</code>: Position for prediction (default: 1)</li><li><code>use_hard_mask</code>: Use hard masking in processor (default: true)</li><li><code>inference_code_layer</code>: Layer for code inference (default: from model.hp)</li></ul><p><strong>Returns</strong></p><ul><li><code>processor</code>: Trained code processor</li><li><code>loss_history</code>: Training loss per epoch</li></ul><p><strong>Example</strong></p><pre><code class="language-julia hljs">proc_wrap = (create_processor=create_code_processor, arch_type=:mbconv,
             predict_from_code=predict_from_code, process_code=process_code)
model, _, _, dl_train, _ = train_final_model(data, create_model; seed=42)
processor, losses = train_code_processor(model, dl_train, proc_wrap; max_epochs=20)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/AutoComputationalGraphTuning.jl/blob/04bc0ca4dc3d73d399fa86f9711e182f3cb7939f/src/final_and_code/train_code_processor.jl#L1-L25">source</a></section></details></article><article><details class="docstring" open="true"><summary id="AutoComputationalGraphTuning.train_epoch!-NTuple{5, Any}"><a class="docstring-binding" href="#AutoComputationalGraphTuning.train_epoch!-NTuple{5, Any}"><code>AutoComputationalGraphTuning.train_epoch!</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Train single epoch</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/AutoComputationalGraphTuning.jl/blob/04bc0ca4dc3d73d399fa86f9711e182f3cb7939f/src/_training/train.jl#L40">source</a></section></details></article><article><details class="docstring" open="true"><summary id="AutoComputationalGraphTuning.train_final_model-Tuple{Any, Function}"><a class="docstring-binding" href="#AutoComputationalGraphTuning.train_final_model-Tuple{Any, Function}"><code>AutoComputationalGraphTuning.train_final_model</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Train final model using combined train+val data, evaluate on test set.</p><p><strong>Arguments</strong></p><ul><li><code>raw_data</code>: Raw input data</li><li><code>create_model</code>: Function to create the model</li><li><code>seed</code>, <code>max_epochs</code>, <code>patience</code>, <code>print_every</code>: Training hyperparameters</li><li><code>randomize_batchsize</code>, <code>normalize_Y</code>, <code>normalization_method</code>, <code>normalization_mode</code>: Data config</li><li><code>use_cuda</code>, <code>loss_spec</code>: Compute settings</li><li><code>model_kwargs...</code>: Additional model arguments</li></ul><p><strong>Returns</strong></p><p><code>(model, stats, train_stats, dl_train, dl_test)</code> where dataloaders can be reused for processor training</p><p><strong>Example</strong></p><pre><code class="language-julia hljs">model, stats, train_stats, dl_train, dl_test = train_final_model(data, create_model; seed=42)
processor, _ = train_code_processor(model, dl_train, proc_wrap)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/AutoComputationalGraphTuning.jl/blob/04bc0ca4dc3d73d399fa86f9711e182f3cb7939f/src/final_and_code/train_finalmodel.jl#L3-L22">source</a></section></details></article><article><details class="docstring" open="true"><summary id="AutoComputationalGraphTuning.train_final_model_from_config-Tuple{Any, Function, TrainingConfig, Any}"><a class="docstring-binding" href="#AutoComputationalGraphTuning.train_final_model_from_config-Tuple{Any, Function, TrainingConfig, Any}"><code>AutoComputationalGraphTuning.train_final_model_from_config</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Train final model from saved config (e.g., best trial from tuning).</p><p><strong>Returns</strong></p><p><code>(model, stats, train_stats, dl_train, dl_test)</code></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/AutoComputationalGraphTuning.jl/blob/04bc0ca4dc3d73d399fa86f9711e182f3cb7939f/src/final_and_code/train_finalmodel.jl#L48-L53">source</a></section></details></article><article><details class="docstring" open="true"><summary id="AutoComputationalGraphTuning.train_model-NTuple{5, Any}"><a class="docstring-binding" href="#AutoComputationalGraphTuning.train_model-NTuple{5, Any}"><code>AutoComputationalGraphTuning.train_model</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Train a model with early stopping and return the best model state and training stats.</p><p><strong>Arguments</strong></p><ul><li><code>compute_loss</code>: Optional custom loss function(model, seq, labels, nan<em>mask) -&gt; (loss, aux</em>info)<ul><li>If not provided, uses standard masked MSE</li><li>Can return auxiliary info dict for logging custom metrics</li><li>Examples: gradient penalties, attention regularization, multi-task losses</li></ul></li></ul><p><strong>Returns</strong></p><ul><li><code>best_model_state</code>: State dict of the best model (lowest validation loss)</li><li><code>training_stats</code>: Dict with training history and final metrics</li></ul><p><strong>Example Custom Loss</strong></p><pre><code class="language-julia hljs"># Gradient penalty example
function my_loss(model, seq, labels, mask)
    # Forward pass (model can return multiple outputs)
    output = model(seq)
    preds = output isa Tuple ? output[1] : output
    
    # Standard prediction loss
    pred_loss = masked_mse(preds, labels, mask)
    
    # Custom regularizer (e.g., gradient penalty)
    grad_penalty = compute_gradient_penalty(model, seq)
    
    total_loss = pred_loss + 0.1 * grad_penalty
    aux = Dict(:pred_loss =&gt; pred_loss, :grad_penalty =&gt; grad_penalty)
    
    (total_loss, aux)
end

# Use it
train_model(model, opt, train_dl, val_dl, ydim; compute_loss=my_loss)

# Or use a compiled loss (3-arg: preds, labels, mask) directly:
train_model(model, opt, train_dl, val_dl, ydim; compiled_loss=my_compiled_loss)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/AutoComputationalGraphTuning.jl/blob/04bc0ca4dc3d73d399fa86f9711e182f3cb7939f/src/_training/train.jl#L66-L105">source</a></section></details></article><article><details class="docstring" open="true"><summary id="AutoComputationalGraphTuning.train_val_test_split-Tuple{Any}"><a class="docstring-binding" href="#AutoComputationalGraphTuning.train_val_test_split-Tuple{Any}"><code>AutoComputationalGraphTuning.train_val_test_split</code></a> — <span class="docstring-category">Method</span></summary><section><div><pre><code class="language-julia hljs">train_val_test_split(data, labels; train_ratio=0.8, val_ratio=0.1, test_ratio=0.1, shuffle=true, seed=nothing)</code></pre><p>Split data and labels together into train/validation/test sets. Uses <code>@views</code> for memory efficiency - returns lightweight views instead of copying data.</p><p><strong>Arguments</strong></p><ul><li><code>data</code>: NamedTuple with fields <code>X</code> (features) and <code>Y</code> (labels)</li><li><code>train_ratio</code>, <code>val_ratio</code>, <code>test_ratio</code>: Proportions for each split (must sum to 1)</li><li><code>_shuffle</code>: Shuffle indices (default: true)</li><li><code>rng</code>: Random number generator (default: Random.GLOBAL_RNG)</li></ul><p><strong>Returns</strong></p><ul><li>Named tuple with <code>(train=(X=..., Y=...), val=(...), test=(...))</code></li><li>All data and labels are views (SubArrays) for memory efficiency</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">data = (X = rand(10, 100), Y = rand(1, 100))
splits, splits_indices = train_val_test_split(data; seed=42)
train_X = splits.train.X
train_Y = splits.train.Y</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/AutoComputationalGraphTuning.jl/blob/04bc0ca4dc3d73d399fa86f9711e182f3cb7939f/src/_data_splitting/split.jl#L15-L38">source</a></section></details></article><article><details class="docstring" open="true"><summary id="AutoComputationalGraphTuning.tune_hyperparameters-Tuple{Any, Function}"><a class="docstring-binding" href="#AutoComputationalGraphTuning.tune_hyperparameters-Tuple{Any, Function}"><code>AutoComputationalGraphTuning.tune_hyperparameters</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Tune hyperparameters across multiple trials with different seeds.</p><p><strong>Returns: (results<em>df, best</em>model, best_info)</strong></p><ul><li>results_df: DataFrame with all trial results</li><li>best_model: Model with highest validation R²</li><li>best<em>info: NamedTuple (seed, r2, batch</em>size) of best trial</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kchu25/AutoComputationalGraphTuning.jl/blob/04bc0ca4dc3d73d399fa86f9711e182f3cb7939f/src/tune/tuning.jl#L3-L10">source</a></section></details></article></article><nav class="docs-footer"><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.16.1 on <span class="colophon-date" title="Thursday 19 February 2026 19:35">Thursday 19 February 2026</span>. Using Julia version 1.12.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
